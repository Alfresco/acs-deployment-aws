# Alfresco Enterprise ACS Deployment AWS
# Copyright (C) 2005 - 2018 Alfresco Software Limited
# License rights for this program may be obtained from Alfresco Software, Ltd.
# pursuant to a written agreement and any use of this program without such an
# agreement is prohibited.

AWSTemplateFormatVersion: "2010-09-09"
Description: "Bastion Stack that is used to provision an EKS Cluster with Worker Nodes in an Auto-Scaling Group."

Metadata:
    AWS::CloudFormation::Interface:
      ParameterGroups:
        - Label:
            default: Bastion Stack Configuration
          Parameters:
            - NumberOfAZs
            - VPCID
            - VPCCIDR
            - PrivateSubnet1ID
            - PrivateSubnet2ID
            - PublicSubnet1ID
            - PublicSubnet2ID
            - EC2LogGroup
            - KeyPairName
            - NodeSecurityGroup
            - RemoteAccessCIDR
            - BastionInstanceType
            - MaxNumberOfBastionNodes
            - MinNumberOfBastionNodes
            - DesiredNumberOfBastionNodes
        - Label:
            default: EKS Worker Nodes Stack Configuration
          Parameters:
            - TemplateBucketName
            - TemplateBucketKeyPrefix
            - NodeInstanceRole
            - NodeInstanceRoleArn
            - NodeInstanceType
            - NodeSecurityGroup
            - MaxNumberOfNodes
            - MinNumberOfNodes
            - DesiredNumberOfNodes
            - NodesMetricsEnabled
            - EksExternalUserArn
            - EKSClusterName
            - K8sNamespace

      ParameterLabels:
        TemplateBucketName:
          default: The name of the S3 bucket that holds the templates
        TemplateBucketKeyPrefix:
          default: The Key prefix for the templates in the S3 template bucket
        NumberOfAZs:
          default: The number of AZ's to deploy into
        VPCID:
          default: The ID of the VPC to deploy the Bastion and EKS Cluster into
        VPCCIDR:
          default: The CIDR block for the VPC to create
        PrivateSubnet1ID:
          default: The ID of the first private subnet to deploy EKS Workers into
        PrivateSubnet2ID:
          default: The ID of the second private subnet to deploy EKS Workers into
        PublicSubnet1ID:
          default: The ID of the first public subet to deploy EKS into
        PublicSubnet2ID:
          default: The ID of the second public subnet to deploy EKS into
        EC2LogGroup:
          default: The bastion log group name
        KeyPairName:
          default: The key pair name to use to access the instances
        RemoteAccessCIDR:
          default: The CIDR block to allow remote access
        BastionInstanceType:
          default: The instance type to deploy Bastion to
        MaxNumberOfBastionNodes:
          default: The maximum number of nodes to scale up to for Bastion
        MinNumberOfBastionNodes:
          default: The minimum number of nodes to scale down to for Bastion
        DesiredNumberOfBastionNodes:
          default: The desired number of nodes to keep running for Bastion
        NodeInstanceRole:
          default: The AWS IAM Role to be applied to the EKS Worker Nodes
        NodeInstanceRoleArn:
          default: The AWS IAM Role ARN to be applied to the EKS Worker Nodes
        NodeInstanceType:
          default: The instance type to deploy EKS Worker Node to
        NodeSecurityGroup:
          default: The Security Group of EKS Worker nodes
        MaxNumberOfNodes:
          default: The maximum number of nodes to scale up to for EKS Worker Node
        MinNumberOfNodes:
          default: The minimum number of nodes to scale down to for EKS Worker Node
        DesiredNumberOfNodes:
          default: The desired number of nodes to keep running for EKS Worker Node
        NodesMetricsEnabled:
          default: Enables all CloudWatch metrics for the nodes auto scaling group
        EksExternalUserArn:
          default: The AWS IAM user arn who will be authorised to connect the cluster externally
        EKSClusterName:
          default: The EKS cluster name
        K8sNamespace:
          default: The namespace in EKS to deploy Helm charts

Parameters:
    TemplateBucketName:
      AllowedPattern: "^[0-9a-zA-Z]+([0-9a-zA-Z-]*[0-9a-zA-Z])*$"
      ConstraintDescription: "Bucket name can include numbers, lowercase letters, uppercase letters, and hyphens (-). It cannot start or end with a hyphen (-)."
      Description: "S3 bucket name that contains the CFN templates (VPC, Bastion etc). This string can include numbers, lowercase letters, uppercase letters, and hyphens (-). It cannot start or end with a hyphen (-)."
      Type: "String"
    TemplateBucketKeyPrefix:
      AllowedPattern: "^[0-9a-zA-Z-/]*$"
      ConstraintDescription: "Template bucket key prefix can include numbers, lowercase letters, uppercase letters, hyphens (-), and forward slash (/)."
      Type: "String"
    NodeSecurityGroup:
      Description: "ID for the VPC, This will be used to get the node security group"
      Type: "AWS::EC2::SecurityGroup::Id"
    VPCID:
      Description: "ID for the VPC"
      Type: "AWS::EC2::VPC::Id"
    PublicSubnet1ID:
      Description: "ID of Public Subnet 1"
      Type: "AWS::EC2::Subnet::Id"
    PublicSubnet2ID:
      Description: "ID of Public Subnet 2"
      Type: "AWS::EC2::Subnet::Id"
    PrivateSubnet1ID:
      Description: "ID of Private Subnet 1"
      Type: "AWS::EC2::Subnet::Id"
    PrivateSubnet2ID:
      Description: "ID of Private Subnet 2"
      Type: "AWS::EC2::Subnet::Id"
    EC2LogGroup:
      Description: The bastion log group name
      Type: "String"
    KeyPairName:
      Description: "The name of an existing public/private key pair, which allows you to securely connect to your instance after it launches"
      Type: "AWS::EC2::KeyPair::KeyName"
    RemoteAccessCIDR:
      AllowedPattern: "^(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])(\\/([0-9]|[1-2][0-9]|3[0-2]))$"
      ConstraintDescription: "CIDR block parameter must be in the form x.x.x.x/x"
      Description: "The CIDR IP range that is permitted to access the AWS resources. It is recommended that you set this value to a trusted IP range."
      Type: "String"
    BastionInstanceType:
      Type: "String"
      Description: "The type of EC2 instance to be launched for Bastion Host"
      AllowedValues:
        # Add more instance types if needed
        - t2.micro
        - t2.medium
        - t2.large
      ConstraintDescription: "Must contain a valid instance type"
    DesiredNumberOfBastionNodes:
      Type: "String"
      MinLength: 1
      Description: "The desired number of Bastion instance to run"
    MaxNumberOfBastionNodes:
      Type: "String"
      MinLength: 1
      Description: "The maximum number of Bastion instances to run"
    MinNumberOfBastionNodes:
      Type: "String"
      MinLength: 1
      Description: "The minimum number of Bastion instances to run"
      Default: 1
    NodeInstanceRole:
      Type: "String"
      Description: "The AWS IAM Role to be applied to the EKS Worker Nodes"
    NodeInstanceRoleArn:
      Type: "String"
      Description: "The AWS IAM Role ARN to be applied to the EKS Worker Nodes"
    NodeInstanceType:
      Type: "String"
      Description: "The type of EC2 instance to be launched for EKS Worker Node"
      AllowedValues:
        # Add more instance types if needed
        - t2.xlarge
        - t2.2xlarge
        - m3.xlarge
        - m3.2xlarge
        - m4.xlarge
        - m4.2xlarge
        - m5.xlarge
        - m5.2xlarge
      ConstraintDescription: "Must contain a valid instance type"
    DesiredNumberOfNodes:
      Type: "String"
      MinLength: 1
      Description: "The desired number of EKS Worker Nodes to run"
    MaxNumberOfNodes:
      Type: "String"
      MinLength: 1
      Description: "The maximum number of EKS Worker Nodes to run"
    MinNumberOfNodes:
      Type: "String"
      MinLength: 1
      Description: "The minimum number of EKS Worker Nodes to run"
    NodesMetricsEnabled:
      Description: Enables all CloudWatch metrics for the nodes auto scaling group
      Type: String
    EksExternalUserArn:
      Type: String
      Description: The AWS IAM user arn who will be authorised to connect the cluster externally
    EKSClusterName:
      Type: String
      Description: The name of the eks cluster
    K8sNamespace:
      Type: String
      Description: The namespace in EKS to deploy Helm charts

Mappings:
  BastionAmiRegionMap:
    us-east-1:
      AmiId: ami-cfe4b2b0
    us-west-2:
      AmiId: ami-0ad99772
  NodeAmiRegionMap:
    us-east-1:
      AmiId: ami-dea4d5a1
    us-west-2:
      AmiId: ami-73a6e20b

Conditions:
  isNodesMetricsEnabled: !Equals [!Ref NodesMetricsEnabled, "true"]

Resources:

  SSHMetricFilter:
    Type: 'AWS::Logs::MetricFilter'
    Properties:
      LogGroupName: !Ref EC2LogGroup
      FilterPattern: ON FROM USER PWD
      MetricTransformations:
        - MetricName: SSHCommandCount
          MetricValue: 1
          MetricNamespace: !Join
            - /
            - - AWSQuickStart
              - !Ref 'AWS::StackName'

  EKSServiceRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Action:
              - sts:AssumeRole
            Effect: Allow
            Principal:
              Service: eks.amazonaws.com
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonEKSClusterPolicy
        - arn:aws:iam::aws:policy/AmazonEKSServicePolicy

  BastionInstanceRole:
    Type: AWS::IAM::Role
    Properties:
      Policies:
        - PolicyName: !Sub "${TemplateBucketName}-s3-policy"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Action:
                  - s3:GetObject
                Resource: !Sub "arn:aws:s3:::${TemplateBucketName}/${TemplateBucketKeyPrefix}/scripts/*"
                Effect: Allow
        - PolicyName: cloudwatch-logs-policy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Action:
                  - logs:CreateLogStream
                  - logs:GetLogEvents
                  - logs:PutLogEvents
                  - logs:DescribeLogGroups
                  - logs:DescribeLogStreams
                  - logs:PutRetentionPolicy
                  - logs:PutMetricFilter
                  - logs:CreateLogGroup
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:${EC2LogGroup}:*"
                Effect: Allow
        - PolicyName: bastion-eip-policy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Action:
                  - ec2:AssociateAddress
                  - ec2:DescribeAddresses
                Resource: "*"
                Effect: Allow
        - PolicyName: eks-cluster-policy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Action:
                  ### This a EKS limitation so far at deployment time
                  ### Bastion should only be able to delete or do anything to its own cluster
                  - eks:*
                  - sts:*
                  - iam:PassRole
                Resource: "*"
                Effect: Allow
      Path: /
      AssumeRolePolicyDocument:
        Statement:
          - Action:
              - sts:AssumeRole
            Principal:
              Service:
                - ec2.amazonaws.com
            Effect: Allow
        Version: "2012-10-17"
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AmazonEC2RoleforSSM

  BastionInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Roles:
        - !Ref BastionInstanceRole
      Path: /

  NodeInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Path: /
      Roles:
      - !Ref NodeInstanceRole

  # Bastion resources
  BastionEIP:
    Type: AWS::EC2::EIP
    Properties:
      Domain: vpc

  BastionAutoScalingGroup:
    Type: AWS::AutoScaling::AutoScalingGroup
    Properties:
      LaunchConfigurationName: !Ref BastionLaunchConfiguration
      VPCZoneIdentifier:
        - !Ref PublicSubnet1ID
        - !Ref PublicSubnet2ID
      MinSize: !Ref MinNumberOfBastionNodes
      MaxSize: !Ref MaxNumberOfBastionNodes
      Cooldown: "300"
      DesiredCapacity: !Ref DesiredNumberOfBastionNodes
      Tags:
        - Key: Name
          Value: !Sub "${AWS::StackName}"
          PropagateAtLaunch: true
        - Key: Component
          Value: ACS-Bastion-AutoScaling-Group
          PropagateAtLaunch: true
    CreationPolicy:
      ResourceSignal:
        Timeout: PT30M

  BastionLaunchConfiguration:
    Type: AWS::AutoScaling::LaunchConfiguration
    Metadata:
      AWS::CloudFormation::Authentication:
        S3AccessCreds:
          type: S3
          roleName: !Ref BastionInstanceRole
          buckets: !Ref TemplateBucketName
      AWS::CloudFormation::Init:
        config:
          packages:
            yum:
              awslogs: []
          files:
            '/etc/awslogs/awscli.conf':
              content: !Sub |
                [default]
                region = ${AWS::Region}
                [plugins]
                cwlogs = cwlogs
              mode: '000644'
              owner: root
              group: root
            '/etc/awslogs/awslogs.conf':
              content: !Sub |
                [general]
                state_file = /var/lib/awslogs/agent-state
                [/var/log/bastion/bastion.log]
                file = /var/log/bastion/bastion.log
                datetime_format = %b %d %H:%M:%S
                log_stream_name = ${AWS::StackName}/bastion-{instance_id}/var/log/bastion/bastion.log
                log_group_name = ${EC2LogGroup}
                [/var/log/dmesg]
                file = /var/log/dmesg
                log_stream_name = ${AWS::StackName}/bastion-{instance_id}/var/log/dmesg
                log_group_name = ${EC2LogGroup}
                [/var/log/messages]
                datetime_format = %b %d %H:%M:%S
                file = /var/log/messages
                log_stream_name = ${AWS::StackName}/bastion-{instance_id}/var/log/messages
                log_group_name = ${EC2LogGroup}
                [/var/log/secure]
                datetime_format = %b %d %H:%M:%S
                file = /var/log/secure
                log_stream_name = ${AWS::StackName}/bastion-{instance_id}/var/log/secure
                log_group_name = ${EC2LogGroup}
                [/var/log/audit/audit.log]
                datetime_format =
                file = /var/log/audit/audit.log
                log_stream_name = ${AWS::StackName}/bastion-{instance_id}/var/log/audit/audit.log
                log_group_name = ${EC2LogGroup}
                [/var/log/cron]
                datetime_format = %b %d %H:%M:%S
                file = /var/log/cron
                log_stream_name = ${AWS::StackName}/bastion-{instance_id}/var/log/cron
                log_group_name = ${EC2LogGroup}
                [/var/log/cfn-init.log]
                datetime_format = %Y-%m-%d %H:%M:%S
                file = /var/log/cfn-init.log
                log_stream_name = ${AWS::StackName}/bastion-{instance_id}/var/log/cfn-init.log
                log_group_name = ${EC2LogGroup}
                [/var/log/cfn-hup.log]
                datetime_format = %Y-%m-%d %H:%M:%S
                file = /var/log/cfn-hup.log
                log_stream_name = ${AWS::StackName}/bastion-{instance_id}/var/log/cfn-hup.log
                log_group_name = ${EC2LogGroup}
                [/var/log/cfn-init-cmd.log]
                datetime_format = %Y-%m-%d %H:%M:%S
                file = /var/log/cfn-init-cmd.log
                log_stream_name = ${AWS::StackName}/bastion-{instance_id}/var/log/cfn-init-cmd.log
                log_group_name = ${EC2LogGroup}
                [/var/log/cloud-init-output.log]
                file = /var/log/cloud-init-output.log
                log_stream_name = ${AWS::StackName}/bastion-{instance_id}/var/log/cloud-init-output.log
                log_group_name = ${EC2LogGroup}
                [/var/log/amazon/ssm/amazon-ssm-agent.log]
                datetime_format = %Y-%m-%d %H:%M:%S
                file = /var/log/amazon/ssm/amazon-ssm-agent.log
                log_stream_name = ${AWS::StackName}/bastion-{instance_id}/var/log/amazon/ssm/amazon-ssm-agent.log
                log_group_name = ${EC2LogGroup}
                [/var/log/amazon/ssm/errors.log]
                datetime_format = %Y-%m-%d %H:%M:%S
                file = /var/log/amazon/ssm/errors.log
                log_stream_name = ${AWS::StackName}/bastion-{instance_id}/var/log/amazon/ssm/errors.log
                log_group_name = ${EC2LogGroup}
                [/var/log/maillog]
                datetime_format = %b %d %H:%M:%S
                file = /var/log/maillog
                log_stream_name = ${AWS::StackName}/bastion-{instance_id}/var/log/maillog
                log_group_name = ${EC2LogGroup}
                [/var/log/yum.log]
                datetime_format = %b %d %H:%M:%S
                file = /var/log/yum.log
                log_stream_name = ${AWS::StackName}/bastion-{instance_id}/var/log/yum.log
                log_group_name = ${EC2LogGroup}
                [/var/log/awslogs.log]
                datetime_format = %Y-%m-%d %H:%M:%S
                file = /var/log/awslogs.log
                log_stream_name = ${AWS::StackName}/bastion-{instance_id}/var/log/awslogs.log
                log_group_name = ${EC2LogGroup}
                [/var/log/boot.log]
                file = /var/log/boot.log
                log_stream_name = ${AWS::StackName}/bastion-{instance_id}/var/log/boot.log
                log_group_name = ${EC2LogGroup}
                [/var/log/cfn-wire.log]
                datetime_format = %Y-%m-%d %H:%M:%S
                file = /var/log/cfn-wire.log
                log_stream_name = ${AWS::StackName}/bastion-{instance_id}/var/log/cfn-wire.log
                log_group_name = ${EC2LogGroup}
              mode: '000644'
              owner: root
              group: root
            /tmp/hardening_bootstrap.sh:
              source: !Sub "https://${TemplateBucketName}.s3.amazonaws.com/${TemplateBucketKeyPrefix}/scripts/hardening_bootstrap.sh"
              mode: "000550"
              owner: root
              group: root
              authentication: S3AccessCreds
            /tmp/eks_bootstrap.sh:
              content: !Sub |
                #!/bin/bash
                echo "Checking whether cluster exists..."
                aws eks describe-cluster --region ${AWS::Region} --name ${EKSClusterName} &> /dev/null
                if [ $? -ne 0 ]; then
                  echo Cluster does not exist, creating...
                  aws eks create-cluster --region ${AWS::Region} \
                  --name ${EKSClusterName} \
                  --role-arn ${EKSServiceRole.Arn} \
                  --resources-vpc-config subnetIds=${PrivateSubnet1ID},${PrivateSubnet2ID},${PublicSubnet1ID},${PublicSubnet2ID},securityGroupIds=${ControlPlaneSecurityGroup}
                  if [ $? -ne 0 ]; then
                    exit 1
                  fi
                  sleep 5
                  STATUS=$(aws eks describe-cluster --region ${AWS::Region} --name ${EKSClusterName} --query cluster.status --output text)
                  while [ \"$STATUS\" = \"CREATING\" ]; do
                    echo Cluster is still creating, sleeping for 30 seconds...
                    sleep 30
                    STATUS=$(aws eks describe-cluster --region ${AWS::Region} --name ${EKSClusterName} --query cluster.status --output text)
                  done
                fi
                echo Updating kubeconfig file...
                ENDPOINT=$(aws eks describe-cluster --region ${AWS::Region}  --name ${EKSClusterName} --query cluster.endpoint --output text)
                CERT_DATA=$(aws eks describe-cluster --region ${AWS::Region}  --name ${EKSClusterName} --query cluster.certificateAuthority.data --output text)
                sed -i s,ENDPOINT,$ENDPOINT,g /home/ec2-user/.kube/config
                sed -i s,CERTIFICATE_DATA,$CERT_DATA,g /home/ec2-user/.kube/config
                export KUBECONFIG=/home/ec2-user/.kube/config
                echo Checking whether aws-auth configmap exists...
                kubectl get configmaps/aws-auth -n kube-system &> /dev/null
                if [ $? -gt 0 ]; then
                  echo Configmap does not exist, applying...
                  kubectl apply -f /tmp/aws-auth-cm.yaml
                fi
                echo Checking whether tiller serviceaccount exists...
                kubectl get serviceaccount/tiller -n kube-system &> /dev/null
                if [ $? -gt 0 ]; then
                  echo tiller serviceaccount does not exist, applying...
                  kubectl apply -f /tmp/helm-rbac-config.yaml
                fi
              mode: "000750"
              owner: root
              group: root
            /tmp/aws-auth-cm.yaml:
              content: !Sub |
                apiVersion: v1
                kind: ConfigMap
                metadata:
                  name: aws-auth
                  namespace: kube-system
                data:
                  mapRoles: |
                    - rolearn: ${NodeInstanceRoleArn}
                      username: system:node:{{EC2PrivateDNSName}}
                      groups:
                        - system:bootstrappers
                        - system:nodes
                  mapUsers: |
                    - userarn: ${EksExternalUserArn}
                      username: admin
                      groups:
                        - system:masters
              mode: "000644"
              owner: root
              group: root
            '/tmp/helm-rbac-config.yaml':
              content: !Sub |
                apiVersion: v1
                kind: ServiceAccount
                metadata:
                  name: tiller
                  namespace: kube-system
                ---
                apiVersion: rbac.authorization.k8s.io/v1beta1
                kind: ClusterRoleBinding
                metadata:
                  name: tiller
                roleRef:
                  apiGroup: rbac.authorization.k8s.io
                  kind: ClusterRole
                  name: cluster-admin
                subjects:
                  - kind: ServiceAccount
                    name: tiller
                    namespace: kube-system
              mode: "000644"
              owner: root
              group: root
            /home/ec2-user/.kube/config:
              content: !Sub |
                apiVersion: v1
                clusters:
                - cluster:
                    server: ENDPOINT
                    certificate-authority-data: CERTIFICATE_DATA
                  name: kubernetes
                contexts:
                - context:
                    cluster: kubernetes
                    user: aws
                  name: aws
                current-context: aws
                kind: Config
                preferences: {}
                users:
                - name: aws
                  user:
                    exec:
                      apiVersion: client.authentication.k8s.io/v1alpha1
                      command: aws-iam-authenticator
                      args:
                        - token
                        - -i
                        - ${EKSClusterName}
              mode: "000666"
              owner: ec2-user
              group: ec2-user
          services:
            sysvinit:
              awslogs:
                enabled: true
                ensureRunning: true
                packages:
                  yum:
                  - awslogs
                files:
                - '/etc/awslogs/awslogs.conf'
                - '/etc/awslogs/awscli.conf'
          commands:
            01_eks-bootstrap:
              command: "./tmp/eks_bootstrap.sh"
            02_bastion-bootstrap:
              command: "./tmp/hardening_bootstrap.sh --tcp-forwarding false --x11-forwarding false"
    Properties:
      AssociatePublicIpAddress: true
      PlacementTenancy: default
      KeyName: !Ref KeyPairName
      IamInstanceProfile: !Ref BastionInstanceProfile
      ImageId: !FindInMap [BastionAmiRegionMap, !Ref "AWS::Region", AmiId]
      SecurityGroups:
        - !Ref BastionSecurityGroup
      InstanceType: !Ref BastionInstanceType
      UserData:
        Fn::Base64: !Sub |
            #!/bin/bash
            set -x
            export PATH=$PATH:/usr/local/bin
            yum install -y https://s3.amazonaws.com/ec2-downloads-windows/SSMAgent/latest/linux_amd64/amazon-ssm-agent.rpm
            pip install awscli --upgrade
            easy_install https://s3.amazonaws.com/cloudformation-examples/aws-cfn-bootstrap-latest.tar.gz
            EIP_LIST=${BastionEIP},Null,Null,Null
            CLOUDWATCHGROUP=${EC2LogGroup}
            curl -o kubectl https://amazon-eks.s3-us-west-2.amazonaws.com/1.10.3/2018-06-05/bin/linux/amd64/kubectl
            chmod +x ./kubectl
            mv kubectl /usr/local/bin
            kubectl version --short --client
            curl -o aws-iam-authenticator https://amazon-eks.s3-us-west-2.amazonaws.com/1.10.3/2018-07-26/bin/linux/amd64/aws-iam-authenticator
            chmod +x ./aws-iam-authenticator
            mv aws-iam-authenticator /usr/local/bin
            aws-iam-authenticator help
            curl -o helm.tar.gz https://storage.googleapis.com/kubernetes-helm/helm-v2.9.1-linux-amd64.tar.gz
            tar xf helm.tar.gz
            mv ./linux-amd64/helm /usr/local/bin
            helm version --client
            cfn-init -v --stack ${AWS::StackName} --resource BastionLaunchConfiguration --region ${AWS::Region}
            cfn-signal -e $? --stack ${AWS::StackName} --resource BastionAutoScalingGroup --region ${AWS::Region}

  BastionSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      Tags:
        - Key: Name
          Value: !Sub "${AWS::StackName}-BastionHost-SG"
      GroupDescription: Enables SSH Access to Bastion Hosts
      VpcId: !Ref VPCID
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: '22'
          ToPort: '22'
          CidrIp: !Ref RemoteAccessCIDR

  # Cluster resources
  ControlPlaneSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      Tags:
        - Key: Name
          Value: !Sub "${AWS::StackName}-ControlPlane-SG"
        - Key: Component
          Value: ACS-EKS-ControlPlane
      GroupDescription: Cluster communication with worker nodes
      VpcId: !Ref VPCID

  NodeSecurityGroupIngressRepoCluster:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      Description: Allow node to communicate with each other repo cluster
      GroupId: !Ref NodeSecurityGroup
      SourceSecurityGroupId: !Ref NodeSecurityGroup
      IpProtocol: tcp
      FromPort: 5701
      ToPort: 5701

  NodeSecurityGroupIngressShareCluster:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      Description: Allow node to communicate with each other share cluster
      GroupId: !Ref NodeSecurityGroup
      SourceSecurityGroupId: !Ref NodeSecurityGroup
      IpProtocol: tcp
      FromPort: 5801
      ToPort: 5810

  NodeSecurityGroupFromBastion:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      Description: Allow bastion to SSH to worker nodes
      GroupId: !Ref NodeSecurityGroup
      SourceSecurityGroupId: !Ref BastionSecurityGroup
      IpProtocol: tcp
      FromPort: 22
      ToPort: 22

  NodeSecurityGroupFromControlPlaneIngress:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      Description: Allow worker Kubelets and pods to receive communication from the cluster control plane
      GroupId: !Ref NodeSecurityGroup
      SourceSecurityGroupId: !Ref ControlPlaneSecurityGroup
      IpProtocol: tcp
      FromPort: 10250
      ToPort: 10250

  ControlPlaneEgressToNodeSecurityGroup:
    Type: AWS::EC2::SecurityGroupEgress
    Properties:
      Description: Allow the cluster control plane to communicate with worker Kubelet and pods
      GroupId: !Ref ControlPlaneSecurityGroup
      DestinationSecurityGroupId: !Ref NodeSecurityGroup
      IpProtocol: tcp
      FromPort: 10250
      ToPort: 10250

  ClusterControlPlaneSecurityGroupIngress:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      Description: Allow pods to communicate with the cluster API Server
      GroupId: !Ref ControlPlaneSecurityGroup
      SourceSecurityGroupId: !Ref NodeSecurityGroup
      IpProtocol: tcp
      ToPort: 443
      FromPort: 443

  NodeAutoScalingGroup:
    DependsOn: BastionAutoScalingGroup
    Type: AWS::AutoScaling::AutoScalingGroup
    Properties:
      DesiredCapacity: !Ref DesiredNumberOfNodes
      LaunchConfigurationName: !Ref NodeLaunchConfig
      MinSize: !Ref MinNumberOfNodes
      MaxSize: !Ref MaxNumberOfNodes
      MetricsCollection:
        !If
      - isNodesMetricsEnabled
      -
        - Granularity: 1Minute
      - !Ref "AWS::NoValue"
      VPCZoneIdentifier:
        - !Ref PrivateSubnet1ID
        - !Ref PrivateSubnet2ID
      Tags:
      - Key: Name
        Value: !Sub "${EKSClusterName}-worker-node"
        PropagateAtLaunch: 'true'
      - Key: !Sub 'kubernetes.io/cluster/${EKSClusterName}'
        Value: 'owned'
        PropagateAtLaunch: 'true'
      - Key: KubernetesCluster
        Value: !Sub "${EKSClusterName}"
        PropagateAtLaunch: true
    UpdatePolicy:
      AutoScalingRollingUpdate:
        MinInstancesInService: !Ref MinNumberOfNodes
        MaxBatchSize: !Ref MaxNumberOfNodes
    CreationPolicy:
      ResourceSignal:
        Count: !Ref DesiredNumberOfNodes
        Timeout: PT30M

  NodeLaunchConfig:
    DependsOn: BastionAutoScalingGroup
    Type: AWS::AutoScaling::LaunchConfiguration
    Metadata:
      AWS::CloudFormation::Authentication:
        S3AccessCreds:
          type: S3
          roleName: !Ref NodeInstanceRole
          buckets: !Ref TemplateBucketName
      AWS::CloudFormation::Init:
        config:
          packages:
            yum:
              awslogs: []
              amazon-ssm-agent: []
              amazon-efs-utils: []
          files:
            '/etc/awslogs/awscli.conf':
              content: !Sub |
                [default]
                region = ${AWS::Region}
                [plugins]
                cwlogs = cwlogs
              mode: '000644'
              owner: root
              group: root
            '/etc/awslogs/awslogs.conf':
              content: !Sub |
                [general]
                state_file = /var/lib/awslogs/agent-state
                [/var/log/bastion/bastion.log]
                file = /var/log/bastion/bastion.log
                datetime_format = %b %d %H:%M:%S
                log_stream_name = ${AWS::StackName}/workernode-{instance_id}/var/log/bastion/bastion.log
                log_group_name = ${EC2LogGroup}
                [/var/log/dmesg]
                file = /var/log/dmesg
                log_stream_name = ${AWS::StackName}/workernode-{instance_id}/var/log/dmesg
                log_group_name = ${EC2LogGroup}
                [/var/log/messages]
                datetime_format = %b %d %H:%M:%S
                file = /var/log/messages
                log_stream_name = ${AWS::StackName}/workernode-{instance_id}/var/log/messages
                log_group_name = ${EC2LogGroup}
                [/var/log/secure]
                datetime_format = %b %d %H:%M:%S
                file = /var/log/secure
                log_stream_name = ${AWS::StackName}/workernode-{instance_id}/var/log/secure
                log_group_name = ${EC2LogGroup}
                [/var/log/audit/audit.log]
                datetime_format =
                file = /var/log/audit/audit.log
                log_stream_name = ${AWS::StackName}/workernode-{instance_id}/var/log/audit/audit.log
                log_group_name = ${EC2LogGroup}
                [/var/log/cron]
                datetime_format = %b %d %H:%M:%S
                file = /var/log/cron
                log_stream_name = ${AWS::StackName}/workernode-{instance_id}/var/log/cron
                log_group_name = ${EC2LogGroup}
                [/var/log/cfn-init.log]
                datetime_format = %Y-%m-%d %H:%M:%S
                file = /var/log/cfn-init.log
                log_stream_name = ${AWS::StackName}/workernode-{instance_id}/var/log/cfn-init.log
                log_group_name = ${EC2LogGroup}
                [/var/log/cfn-hup.log]
                datetime_format = %Y-%m-%d %H:%M:%S
                file = /var/log/cfn-hup.log
                log_stream_name = ${AWS::StackName}/workernode-{instance_id}/var/log/cfn-hup.log
                log_group_name = ${EC2LogGroup}
                [/var/log/cfn-init-cmd.log]
                datetime_format = %Y-%m-%d %H:%M:%S
                file = /var/log/cfn-init-cmd.log
                log_stream_name = ${AWS::StackName}/workernode-{instance_id}/var/log/cfn-init-cmd.log
                log_group_name = ${EC2LogGroup}
                [/var/log/cloud-init-output.log]
                file = /var/log/cloud-init-output.log
                log_stream_name = ${AWS::StackName}/workernode-{instance_id}/var/log/cloud-init-output.log
                log_group_name = ${EC2LogGroup}
                [/var/log/amazon/ssm/amazon-ssm-agent.log]
                datetime_format = %Y-%m-%d %H:%M:%S
                file = /var/log/amazon/ssm/amazon-ssm-agent.log
                log_stream_name = ${AWS::StackName}/workernode-{instance_id}/var/log/amazon/ssm/amazon-ssm-agent.log
                log_group_name = ${EC2LogGroup}
                [/var/log/amazon/ssm/errors.log]
                datetime_format = %Y-%m-%d %H:%M:%S
                file = /var/log/amazon/ssm/errors.log
                log_stream_name = ${AWS::StackName}/workernode-{instance_id}/var/log/amazon/ssm/errors.log
                log_group_name = ${EC2LogGroup}
                [/var/log/maillog]
                datetime_format = %b %d %H:%M:%S
                file = /var/log/maillog
                log_stream_name = ${AWS::StackName}/workernode-{instance_id}/var/log/maillog
                log_group_name = ${EC2LogGroup}
                [/var/log/yum.log]
                datetime_format = %b %d %H:%M:%S
                file = /var/log/yum.log
                log_stream_name = ${AWS::StackName}/workernode-{instance_id}/var/log/yum.log
                log_group_name = ${EC2LogGroup}
                [/var/log/kube-proxy.log]
                datetime_format =
                file = /var/log/kube-proxy.log
                log_stream_name = ${AWS::StackName}/workernode-{instance_id}/var/log/kube-proxy.log
                log_group_name = ${EC2LogGroup}
                [/var/log/awslogs.log]
                datetime_format = %Y-%m-%d %H:%M:%S
                file = /var/log/awslogs.log
                log_stream_name = ${AWS::StackName}/workernode-{instance_id}/var/log/awslogs.log
                log_group_name = ${EC2LogGroup}
                [/var/log/boot.log]
                file = /var/log/boot.log
                log_stream_name = ${AWS::StackName}/workernode-{instance_id}/var/log/boot.log
                log_group_name = ${EC2LogGroup}
                [/var/log/cfn-wire.log]
                datetime_format = %Y-%m-%d %H:%M:%S
                file = /var/log/cfn-wire.log
                log_stream_name = ${AWS::StackName}/workernode-{instance_id}/var/log/cfn-wire.log
                log_group_name = ${EC2LogGroup}
              mode: '000644'
              owner: root
              group: root
            '/tmp/hardening_bootstrap.sh':
              source: !Sub "https://${TemplateBucketName}.s3.amazonaws.com/${TemplateBucketKeyPrefix}/scripts/hardening_bootstrap.sh"
              mode: "000550"
              owner: root
              group: root
              authentication: S3AccessCreds
          services:
            sysvinit:
              awslogsd:
                enabled: true
                ensureRunning: true
                packages:
                  yum:
                  - awslogs
                files:
                - '/etc/awslogs/awslogs.conf'
                - '/etc/awslogs/awscli.conf'
              amazon-ssm-agent:
                enabled: true
                ensureRunning: true
                packages:
                  yum:
                  - amazon-ssm-agent
              postfix:
                enabled: false
                ensureRunning: false
          commands:
              bastion-bootstrap:
                command: "./tmp/hardening_bootstrap.sh --tcp-forwarding false --x11-forwarding false"
    Properties:
      AssociatePublicIpAddress: false
      IamInstanceProfile: !Ref NodeInstanceProfile
      ImageId: !FindInMap [NodeAmiRegionMap, !Ref "AWS::Region", AmiId]
      InstanceType: !Ref NodeInstanceType
      KeyName: !Ref KeyPairName
      SecurityGroups:
      - !Ref NodeSecurityGroup
      UserData:
        Fn::Base64: !Sub |
            #!/bin/bash -xe
            CLOUDWATCHGROUP=${EC2LogGroup}
            CA_CERTIFICATE_DIRECTORY=/etc/kubernetes/pki
            CA_CERTIFICATE_FILE_PATH=$CA_CERTIFICATE_DIRECTORY/ca.crt
            MODEL_DIRECTORY_PATH=~/.aws/eks
            MODEL_FILE_PATH=$MODEL_DIRECTORY_PATH/eks-2017-11-01.normal.json
            mkdir -p $CA_CERTIFICATE_DIRECTORY
            mkdir -p $MODEL_DIRECTORY_PATH
            curl -o $MODEL_FILE_PATH https://s3-us-west-2.amazonaws.com/amazon-eks/1.10.3/2018-06-05/eks-2017-11-01.normal.json
            aws configure add-model --service-model file://$MODEL_FILE_PATH --service-name eks
            aws eks describe-cluster --region=${AWS::Region} --name=${EKSClusterName} --query 'cluster.{certificateAuthorityData:certificateAuthority.data,endpoint:endpoint}' > /tmp/describe_cluster_result.json
            cat /tmp/describe_cluster_result.json | grep certificateAuthorityData | awk '{print $2}' | sed 's/[,\"]//g' | base64 -d >  $CA_CERTIFICATE_FILE_PATH
            MASTER_ENDPOINT=$(cat /tmp/describe_cluster_result.json | grep endpoint | awk '{print $2}' | sed 's/[,\"]//g')
            INTERNAL_IP=$(curl -s http://169.254.169.254/latest/meta-data/local-ipv4)
            sed -i s,MASTER_ENDPOINT,$MASTER_ENDPOINT,g /var/lib/kubelet/kubeconfig
            sed -i s,CLUSTER_NAME,${EKSClusterName},g /var/lib/kubelet/kubeconfig
            sed -i s,REGION,${AWS::Region},g /etc/systemd/system/kubelet.service
            sed -i s,MAX_PODS,58,g /etc/systemd/system/kubelet.service
            sed -i s,MASTER_ENDPOINT,$MASTER_ENDPOINT,g /etc/systemd/system/kubelet.service
            sed -i s,INTERNAL_IP,$INTERNAL_IP,g /etc/systemd/system/kubelet.service
            DNS_CLUSTER_IP=10.100.0.10
            if [[ $INTERNAL_IP == 10.* ]] ; then DNS_CLUSTER_IP=172.20.0.10; fi
            sed -i s,DNS_CLUSTER_IP,$DNS_CLUSTER_IP,g  /etc/systemd/system/kubelet.service
            sed -i s,CERTIFICATE_AUTHORITY_FILE,$CA_CERTIFICATE_FILE_PATH,g /var/lib/kubelet/kubeconfig
            sed -i s,CLIENT_CA_FILE,$CA_CERTIFICATE_FILE_PATH,g  /etc/systemd/system/kubelet.service
            systemctl daemon-reload
            systemctl restart kubelet
            yum install -y amazon-efs-utils
            /opt/aws/bin/cfn-init -v --stack ${AWS::StackName} --resource NodeLaunchConfig --region ${AWS::Region}
            /opt/aws/bin/cfn-signal -e $? --stack ${AWS::StackName} --resource NodeAutoScalingGroup --region ${AWS::Region}

  EksHelperLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
                - events.amazonaws.com
            Action:
              - sts:AssumeRole
      Policies:
        - PolicyName: EksHelperLambdaRoleLoggingPolicy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource:
                  - !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*"
        - PolicyName: EksHelperLambdaRolePolicy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - eks:DescribeCluster
                  - eks:DeleteCluster
                Resource:
                  - !Sub "arn:aws:eks:${AWS::Region}:${AWS::AccountId}:cluster/${EKSClusterName}"
        - PolicyName: s3GetObjectPolicy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                Resource:
                  - !Sub "arn:aws:s3:::${TemplateBucketName}"
                  - !Sub "arn:aws:s3:::${TemplateBucketName}/${TemplateBucketKeyPrefix}/lambdas/eks-helper-lambda.zip"

  EksHelperLambda:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        S3Bucket: !Ref TemplateBucketName
        S3Key: !Sub "${TemplateBucketKeyPrefix}/lambdas/eks-helper-lambda.zip"
      Handler: eksHelperLambda.handler
      Role: !GetAtt EksHelperLambdaRole.Arn
      Runtime: python2.7
      Timeout: 60
      Description: "A custom resource to manage EKS Cluster used for deploying ACS"

  EksHelperLambdaCustomResource:
    Type: Custom::EksHelper
    DependsOn: BastionAutoScalingGroup
    Properties:
      ServiceToken: !GetAtt EksHelperLambda.Arn
      EKSName: !Ref EKSClusterName

Outputs:
  SubstackName:
    Description: The bastion stack name
    Value: !Sub "${AWS::StackName}"
  BastionSecurityGroup:
    Description: The bastion security group id
    Value: !Ref BastionSecurityGroup
  BastionLaunchConfiguration:
    Description: The bastion host launch config
    Value: !Ref BastionLaunchConfiguration
  BastionAutoScalingGroup:
    Description: The Bastion host autoscaling group
    Value: !Ref BastionAutoScalingGroup
  BastionEIP:
    Description: The Elastic IP of Bastion host
    Value: !Ref BastionEIP
  BastionInstanceProfile:
    Description: IAM Instance profile of Bastion host
    Value: !Ref BastionInstanceProfile
  BastionInstanceRole:
    Description: IAM Role of Bastion host
    Value: !Ref BastionInstanceRole
  ControlPlaneSecurityGroup:
    Description: The ControlPlane security group id
    Value: !Ref ControlPlaneSecurityGroup
  EksClusterName:
    Description: EKS Cluster name
    Value: !Ref EKSClusterName
  EksEndpoint:
    Description: EKS Cluster endpoint
    Value: !GetAtt EksHelperLambdaCustomResource.endpoint
  EksCertAuthority:
    Description: EKS Cluster endpoint certificate authority
    Value: !GetAtt EksHelperLambdaCustomResource.certificateAuthority
  EksServiceRoleArn:
    Value: !GetAtt EKSServiceRole.Arn
  EksServiceRoleArn:
    Value: !GetAtt EKSServiceRole.Arn